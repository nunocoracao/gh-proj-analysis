{
  "results": {
    "dockerfile": {
      "exist": true,
      "count": 1,
      "rootCount": 0,
      "subFolderCount": 1,
      "filepaths": [
        "AzureML-BERT.git/finetune/PyTorch/dockerfile"
      ]
    },
    "composefile": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "devcontainer": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "kustomize": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "helm": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "k8s": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "backstage": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "terraform": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    }
  },
  "info": {
    "id": 160595817,
    "name": "AzureML-BERT",
    "full_name": "microsoft/AzureML-BERT",
    "owner": {
      "login": "microsoft",
      "html_url": "https://github.com/microsoft",
      "type": "Organization"
    },
    "html_url": "https://github.com/microsoft/AzureML-BERT",
    "description": "End-to-End recipes for pre-training and fine-tuning BERT using Azure Machine Learning Service",
    "url": "https://api.github.com/repos/microsoft/AzureML-BERT",
    "clone_url": "https://github.com/microsoft/AzureML-BERT.git",
    "homepage": "https://azure.microsoft.com/en-us/blog/microsoft-makes-it-easier-to-build-popular-language-representation-model-bert-at-large-scale/",
    "size": 327,
    "stargazers_count": 370,
    "watchers_count": 370,
    "language": "Jupyter Notebook"
  }
}