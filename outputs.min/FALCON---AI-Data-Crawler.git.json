{
  "results": {
    "dockerfile": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "composefile": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "devcontainer": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "kustomize": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "helm": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "k8s": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "backstage": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "terraform": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    }
  },
  "info": {
    "id": 284108401,
    "name": "FALCON---AI-Data-Crawler",
    "full_name": "gurtejrehal/FALCON---AI-Data-Crawler",
    "owner": {
      "login": "gurtejrehal",
      "html_url": "https://github.com/gurtejrehal",
      "type": "User"
    },
    "html_url": "https://github.com/gurtejrehal/FALCON---AI-Data-Crawler",
    "description": "Falcon Search has been created to aid the National Crime Records Bureau keeping in mind the need for an efficient AI data crawler that collects classified data from the web based on given keywords. It is a SaaS web data integration (WDI) platform which converts unstructured web data into structured format by extracting, preparing and integrating web data in areas of crime for consumption in criminal investigation agencies.    Falcon provides a visual environment for automating the workflow of extracting and transforming web data. After specifying the target website url, the web data extraction module provides a visual environment for designing automated workflows for harvesting data, going beyond HTML/XML parsing of static content to automate end user interactions yielding data that would otherwise not be immediately visible. Once extracted, the software provides full data preparation capabilities that are used for harmonizing and cleansing the web data.   For consuming the results, Falcon provides several options. It has its own visualization and dashboarding module to help criminal investigators gain the insights that they need. It also provides APIs that offer full access to everything that can be done on our platform, allowing web data to be integrated directly.     FALCON is capable of crawling ten million links and scrape one million links per month using Celery Worker. It moreover has the potential of outperforming this number if tested under standard cloud platforms. ",
    "url": "https://api.github.com/repos/gurtejrehal/FALCON---AI-Data-Crawler",
    "clone_url": "https://github.com/gurtejrehal/FALCON---AI-Data-Crawler.git",
    "homepage": null,
    "size": 96061,
    "stargazers_count": 27,
    "watchers_count": 27,
    "language": "JavaScript"
  }
}