{
  "results": {
    "dockerfile": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "composefile": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "devcontainer": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "kustomize": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "helm": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "k8s": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "backstage": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "terraform": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    }
  },
  "info": {
    "id": 195688835,
    "name": "PySpark-Confluent-Kafka-Apache-Drill-",
    "full_name": "salinaaaaaa/PySpark-Confluent-Kafka-Apache-Drill-",
    "owner": {
      "login": "salinaaaaaa",
      "html_url": "https://github.com/salinaaaaaa",
      "type": "User"
    },
    "html_url": "https://github.com/salinaaaaaa/PySpark-Confluent-Kafka-Apache-Drill-",
    "description": "A code-based  tutorial for production level data streaming with PySpark plus Optimus for data cleaning, Confluent Kafka, & Apache Drill using Docker and Cassandra (NoSQL DB) for storage; This allows for for fast feature engineering and data cleaning.",
    "url": "https://api.github.com/repos/salinaaaaaa/PySpark-Confluent-Kafka-Apache-Drill-",
    "clone_url": "https://github.com/salinaaaaaa/PySpark-Confluent-Kafka-Apache-Drill-.git",
    "homepage": "",
    "size": 1816,
    "stargazers_count": 24,
    "watchers_count": 24,
    "language": "Jupyter Notebook"
  }
}