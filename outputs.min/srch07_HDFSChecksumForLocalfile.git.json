{
  "results": {
    "dockerfile": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "composefile": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "devcontainer": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "kustomize": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "helm": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "k8s": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "backstage": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "terraform": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    }
  },
  "info": {
    "id": 73260693,
    "name": "HDFSChecksumForLocalfile",
    "full_name": "srch07/HDFSChecksumForLocalfile",
    "owner": {
      "login": "srch07",
      "html_url": "https://github.com/srch07",
      "type": "User"
    },
    "html_url": "https://github.com/srch07/HDFSChecksumForLocalfile",
    "description": "This program / jar creates checksum, with same algorithm that hadoop uses to create on hdfs files. So integrity of file can be verified on local and hadoop system. Can also, be used to check if file exist based on checksum, before uploading and cluttering hdfs with duplicate files.",
    "url": "https://api.github.com/repos/srch07/HDFSChecksumForLocalfile",
    "clone_url": "https://github.com/srch07/HDFSChecksumForLocalfile.git",
    "homepage": null,
    "size": 19831,
    "stargazers_count": 22,
    "watchers_count": 22,
    "language": "Java"
  }
}