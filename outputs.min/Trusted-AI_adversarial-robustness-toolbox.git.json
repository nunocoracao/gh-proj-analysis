{
  "results": {
    "dockerfile": {
      "exist": true,
      "count": 8,
      "rootCount": 1,
      "subFolderCount": 7,
      "filepaths": [
        "adversarial-robustness-toolbox.git/Dockerfile",
        "adversarial-robustness-toolbox.git/.github/actions/deepspeech-v2/Dockerfile",
        "adversarial-robustness-toolbox.git/.github/actions/deepspeech-v3/Dockerfile",
        "adversarial-robustness-toolbox.git/.github/actions/espresso/Dockerfile",
        "adversarial-robustness-toolbox.git/.github/actions/goturn/Dockerfile",
        "adversarial-robustness-toolbox.git/.github/actions/tf-faster-rcnn/Dockerfile",
        "adversarial-robustness-toolbox.git/.github/actions/yolo/Dockerfile",
        "adversarial-robustness-toolbox.git/utils/mlops/kubeflow/robustness_evaluation_fgsm_pytorch/Dockerfile"
      ]
    },
    "composefile": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "devcontainer": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "kustomize": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "helm": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "k8s": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "backstage": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "terraform": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    }
  },
  "info": {
    "id": 125381318,
    "name": "adversarial-robustness-toolbox",
    "full_name": "Trusted-AI/adversarial-robustness-toolbox",
    "owner": {
      "login": "Trusted-AI",
      "html_url": "https://github.com/Trusted-AI",
      "type": "Organization"
    },
    "html_url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox",
    "description": "Adversarial Robustness Toolbox (ART) - Python Library for Machine Learning Security - Evasion, Poisoning, Extraction, Inference - Red and Blue Teams",
    "url": "https://api.github.com/repos/Trusted-AI/adversarial-robustness-toolbox",
    "clone_url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox.git",
    "homepage": "https://adversarial-robustness-toolbox.readthedocs.io/en/latest/",
    "size": 401370,
    "stargazers_count": 3387,
    "watchers_count": 3387,
    "language": "Python"
  }
}