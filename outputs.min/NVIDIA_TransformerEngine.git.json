{
  "results": {
    "dockerfile": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "composefile": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "devcontainer": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "kustomize": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "helm": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "k8s": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "backstage": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    },
    "terraform": {
      "exist": false,
      "count": 0,
      "rootCount": 0,
      "subFolderCount": 0,
      "filepaths": []
    }
  },
  "info": {
    "id": 539057023,
    "name": "TransformerEngine",
    "full_name": "NVIDIA/TransformerEngine",
    "owner": {
      "login": "NVIDIA",
      "html_url": "https://github.com/NVIDIA",
      "type": "Organization"
    },
    "html_url": "https://github.com/NVIDIA/TransformerEngine",
    "description": "A library for accelerating Transformer models on NVIDIA GPUs, including using 8-bit floating point (FP8) precision on Hopper GPUs, to provide better performance with lower memory utilization in both training and inference.",
    "url": "https://api.github.com/repos/NVIDIA/TransformerEngine",
    "clone_url": "https://github.com/NVIDIA/TransformerEngine.git",
    "homepage": "https://docs.nvidia.com/deeplearning/transformer-engine/user-guide/index.html",
    "size": 239,
    "stargazers_count": 312,
    "watchers_count": 312,
    "language": "Cuda"
  }
}